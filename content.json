[{"title":"mysql性能优化","date":"2017-10-24T12:12:13.000Z","path":"2017/10/24/mysql性能优化/","text":"一、 优化概述MySQL数据库是常见的两个瓶颈是CPU和I/O的瓶颈，CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候。磁盘I/O瓶颈发生在装入数据远大于内存容量的时候，如果应用分布在网络上，那么查询量相当大的时候那么平瓶颈就会出现在网络上，我们可以用mpstat, iostat, sar和vmstat来查看系统的性能状态。 除了服务器硬件的性能瓶颈，对于MySQL系统本身，我们可以使用工具来优化数据库的性能，通常有三种：使用索引，使用EXPLAIN分析查询以及调整MySQL的内部配置。 二、查询与索引优化分析在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有慢查询日志，EXPLAIN 分析查询，profiling分析以及show命令查询系统状态及系统变量，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。 性能瓶颈定位Show命令我们可以通过show命令查看MySQL状态及变量，找到系统的瓶颈： 1234567891011Mysql&gt; show status ——显示状态信息（扩展show status like ‘XXX’）Mysql&gt; show variables ——显示系统变量（扩展show variables like ‘XXX’）Mysql&gt; show innodb status ——显示InnoDB存储引擎的状态Mysql&gt; show processlist ——查看当前SQL执行，包括执行状态、是否锁表等Shell&gt; mysqladmin variables -u username -p password——显示系统变量Shell&gt; mysqladmin extended-status -u username -p password——显示状态信息 查看状态变量及帮助： 1Shell&gt; mysqld –verbose –help [|more #逐行显示] 比较全的Show命令的使用可参考： http://blog.phpbean.com/a.cn/18/ 慢查询日志 慢查询日志开启： 在配置文件my.cnf或my.ini中在[mysqld]一行下面加入两个配置参数 123log-slow-queries=/data/mysqldata/slow-query.loglong_query_time=2 注：log-slow-queries参数为慢查询日志存放的位置，一般这个目录要有mysql的运行帐号的可写权限，一般都将这个目录设置为mysql的数据存放目录； long_query_time=2中的2表示查询超过两秒才记录； 在my.cnf或者my.ini中添加log-queries-not-using-indexes参数，表示记录下没有使用索引的查询。 log-slow-queries=/data/mysqldata/slow-query.log long_query_time=10 log-queries-not-using-indexes 慢查询日志开启方法二： 我们可以通过命令行设置变量来即时启动慢日志查询。由下面代码可知慢日志没有打开，slow_launch_time=# 表示如果建立线程花费了比这个值更长的时间,slow_launch_threads 计数器将增加 123456789mysql&gt; show variables like &apos;slow%&apos;;+---------------------+-----------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------+| slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | /usr/local/mysql/var/localhost-slow.log |+---------------------+-----------------------------------------+3 rows in set (0.00 sec) 设置慢日志开启12345678910111213141516171819202122mysql&gt; show variables like &apos;slow%&apos;;+---------------------+-----------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------+| slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | /usr/local/mysql/var/localhost-slow.log |+---------------------+-----------------------------------------+3 rows in set (0.00 sec)mysql&gt; set global slow_query_log = on;Query OK, 0 rows affected (0.05 sec)mysql&gt; show variables like &apos;slow%&apos;;+---------------------+-----------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------+| slow_launch_time | 2 || slow_query_log | ON || slow_query_log_file | /usr/local/mysql/var/localhost-slow.log |+---------------------+-----------------------------------------+3 rows in set (0.00 sec) MySQL后可以查询long_query_time 的值 。 1234567mysql&gt; show variables like &apos;long%&apos;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+1 row in set (0.01 sec) 为了方便测试，可以将修改慢查询时间为1秒。12345678910mysql&gt; set long_query_time = 5;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &apos;long%&apos;;+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 5.000000 |+-----------------+----------+1 row in set (0.00 sec) 慢查询分析mysqldumpslow我们可以通过打开log文件查看得知哪些SQL执行效率低下 123456789[root@localhost mysql]# more slow-query.log# Time: 081026 19:46:34# User@Host: root[root] @ localhost []# Query_time: 11 Lock_time: 0 Rows_sent: 1 Rows_examined: 6552961select count(*) from t_user; 从日志中，可以发现查询时间超过5 秒的SQL，而小于5秒的没有出现在此日志中。 如果慢查询日志中记录内容很多，可以使用mysqldumpslow工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。mysqldumpslow对日志文件进行了分类汇总，显示汇总后摘要结果。 进入log的存放目录，运行 1234567[root@mysql_data]#mysqldumpslow slow-query.logReading mysql slow query log from slow-query.logCount: 2 Time=11.00s (22s) Lock=0.00s (0s) Rows=1.0 (2), root[root]@mysqlselect count(N) from t_user; mysqldumpslow命令 1/path/mysqldumpslow -s c -t 10 /database/mysql/slow-query.log 这会输出记录次数最多的10条SQL语句，其中： -s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒叙； -t, 是top n的意思，即为返回前面多少条的数据； -g, 后边可以写一个正则匹配模式，大小写不敏感的； 例如：1/path/mysqldumpslow -s r -t 10 /database/mysql/slow-log 得到返回记录集最多的10个查询。1/path/mysqldumpslow -s t -t 10 -g “left join” /database/mysql/slow-log 得到按照时间排序的前10条里面含有左连接的查询语句。 使用mysqldumpslow命令可以非常明确的得到各种我们需要的查询语句，对MySQL查询语句的监控、分析、优化是MySQL优化非常重要的一步。开启慢查询日志后，由于日志记录操作，在一定程度上会占用CPU资源影响mysql的性能，但是可以阶段性开启来定位性能瓶颈。 explain分析查询使用 EXPLAIN 关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。通过explain命令可以得到: 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; describe t_web_log;+------------+----------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+------------+----------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || uid | smallint(5) unsigned | NO | MUL | NULL | || ip | char(15) | NO | MUL | NULL | || location | varchar(255) | NO | | NULL | || os | varchar(255) | NO | | NULL | || browser | varchar(255) | NO | | NULL | || url | varchar(255) | NO | | NULL | || module | char(6) | NO | MUL | NULL | || controller | varchar(255) | NO | MUL | NULL | || action | varchar(255) | NO | | | || method | varchar(10) | NO | MUL | GET | || data | text | NO | | NULL | || otime | int(10) unsigned | NO | MUL | NULL | |+------------+----------------------+------+-----+---------+----------------+13 rows in set (0.01 sec)mysql&gt; EXPLAIN SELECT * FROM t_web_log WHERE controller = &apos;Login&apos; -&gt; ;+----+-------------+-----------+------+---------------+------------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+---------------+------------+---------+-------+------+-------------+| 1 | SIMPLE | t_web_log | ref | controller | controller | 767 | const | 245 | Using where |+----+-------------+-----------+------+---------------+------------+---------+-------+------+-------------+1 row in set (0.00 sec)mysql&gt; EXPLAIN SELECT * FROM t_web_log WHERE controller = &apos;Login&apos; AND uid = 1 -&gt; ;+----+-------------+-----------+------+----------------+------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+----------------+------+---------+-------+------+-------------+| 1 | SIMPLE | t_web_log | ref | uid,controller | uid | 2 | const | 40 | Using where |+----+-------------+-----------+------+----------------+------+---------+-------+------+-------------+1 row in set (0.00 sec) EXPLAIN字段： Table：显示这一行的数据是关于哪张表的 possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句 key：实际使用的索引。如果为NULL，则没有使用索引。MYSQL很少会选择优化不足的索引，此时可以在SELECT语句中使用USE INDEX（index）来强制使用一个索引或者用IGNORE INDEX（index）来强制忽略索引 key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref：显示索引的哪一列被使用了，如果可能的话，是一个常数 rows：MySQL认为必须检索的用来返回请求数据的行数 type：这是最重要的字段之一，显示查询使用了何种类型。从最好到最差的连接类型为system、const、eq_reg、ref、range、index和ALL system、const：可以将查询的变量转为常量. 如id=1; id为 主键或唯一键. eq_ref：访问索引,返回某单一行的数据.(通常在联接时出现，查询使用的索引为主键或惟一键) ref：访问索引,返回某个值的数据.(可以返回多行) 通常使用=时发生 range：这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西，并且该字段上建有索引时发生的情况(注:不一定好于index) index：以索引的顺序进行全表扫描，优点是不用排序,缺点是还要全表扫描 ALL：全表扫描，应该尽量避免 Extra：关于MYSQL如何解析查询的额外信息，主要有以下几种 using index：只用到索引,可以避免访问表. using where：使用到where来过虑数据. 不是所有的where clause都要显示using where. 如以=方式访问索引. using tmporary：用到临时表 using filesort：用到额外的排序. (当使用order by v1,而没用到索引时,就会使用额外的排序) range checked for eache record(index map:N)：没有好的索引. 1EXPLAIN SELECT * FROM t_web_log WHERE uid &gt; 1 profiling分析查询通过慢日志查询可以知道哪些SQL语句执行效率低下，通过explain我们可以得知SQL语句的具体执行情况，索引使用等，还可以结合show命令查看执行状态。 如果觉得explain的信息不够详细，可以同通过profiling命令得到更准确的SQL执行消耗系统资源的信息。 profiling默认是关闭的。可以通过以下语句查看 1234567mysql&gt; select @@profiling;+-------------+| @@profiling |+-------------+| 0 |+-------------+1 row in set (0.00 sec) 打开功能： mysql&gt;set profiling=1; 执行需要测试的sql 语句： 123456789101112131415161718192021222324252627mysql&gt; set profiling=1;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM t_web_log WHERE uid &gt; 1;ERROR 1046 (3D000): No database selectedmysql&gt; use whmj_agent;Database changedmysql&gt; SELECT * FROM t_web_log WHERE uid &gt; 1;Empty set (0.00 sec)mysql&gt; show profiles\\G;*************************** 1. row ***************************Query_ID: 1Duration: 0.00020475 Query: SELECT * FROM t_web_log WHERE uid &gt; 1*************************** 2. row ***************************Query_ID: 2Duration: 0.00007125 Query: SELECT DATABASE()*************************** 3. row ***************************Query_ID: 3Duration: 0.00015775 Query: SELECT * FROM t_web_log WHERE uid &gt; 13 rows in set (0.00 sec)ERROR:No query specified 123mysql&gt; show profiles\\G; 可以得到被执行的SQL语句的时间和IDmysql&gt;show profile for query 1; 得到对应SQL语句执行的详细信息 Show Profile命令格式：12345678910111213141516171819202122232425SHOW PROFILE [type [, type] … ] [FOR QUERY n] [LIMIT row_count [OFFSET offset]]type: ALL | BLOCK IO | CONTEXT SWITCHES | CPU | IPC | MEMORY | PAGE FAULTS | SOURCE | SWAPS 以上的16rows是针对非常简单的select语句的资源信息，对于较复杂的SQL语句，会有更多的行和字段，比如converting HEAP to MyISAM 、Copying to tmp table等等，由于以上的SQL语句不存在复杂的表操作，所以未显示这些字段。通过profiling资源耗费信息，我们可以采取针对性的优化措施。 测试完毕以后 ，关闭参数：1mysql&gt; set profiling=0 三、索引及查询优化索引的类型 普通索引：这是最基本的索引类型，没唯一性之类的限制。 唯一性索引：和普通索引基本相同，但所有的索引列值保持唯一性。 主键：主键是一种唯一索引，但必须指定为”PRIMARY KEY”。 全文索引：MYSQL从3.23.23开始支持全文索引和全文检索。在MYSQL中，全文索引的索引类型为FULLTEXT。全文索引可以在VARCHAR或者TEXT类型的列上创建。 大多数MySQL索引(PRIMARY KEY、UNIQUE、INDEX和FULLTEXT)使用B树中存储。空间列类型的索引使用R-树，MEMORY表支持hash索引。 单列索引和多列索引（复合索引） 索引可以是单列索引，也可以是多列索引。对相关的列使用索引是提高SELECT操作性能的最佳途径之一。 多列索引MySQL可以为多个列创建索引。一个索引可以包括15个列。对于某些列类型，可以索引列的左前缀，列的顺序非常重要。 多列索引可以视为包含通过连接索引列的值而创建的值的排序的数组。一般来说，即使是限制最严格的单列索引，它的限制能力也远远低于多列索引。 最左前缀 多列索引有一个特点，即最左前缀（Leftmost Prefixing）。假如有一个多列索引为key(firstname lastname age)，当搜索条件是以下各种列的组合和顺序时，MySQL将使用该多列索引： firstname，lastname，age firstname，lastname firstname 也就是说，相当于还建立了key(firstname lastname)和key(firstname)。 索引主要用于下面的操作： 快速找出匹配一个WHERE子句的行。 删除行。当执行联接时，从其它表检索行。 对具体有索引的列key_col找出MAX()或MIN()值。由预处理器进行优化，检查是否对索引中在key_col之前发生所有关键字元素使用了WHERE keypart# = constant。在这种情况下，MySQL为每个MIN()或MAX()表达式执行一次关键字查找，并用常数替换它。如果所有表达式替换为常量，查询立即返回。例如： SELECT MIN(key2), MAX (key2) FROM tb WHERE key1=10; 如果对一个可用关键字的最左面的前缀进行了排序或分组(例如，ORDER BY key_part_1,key_part_2)，排序或分组一个表。如果所有关键字元素后面有DESC，关键字以倒序被读取。 在一些情况中，可以对一个查询进行优化以便不用查询数据行即可以检索值。如果查询只使用来自某个表的数字型并且构成某些关键字的最左面前缀的列，为了更快，可以从索引树检索出值。 SELECT key_part3 FROM tb WHERE key_part1=1 有时MySQL不使用索引，即使有可用的索引。一种情形是当优化器估计到使用索引将需要MySQL访问表中的大部分行时。(在这种情况下，表扫描可能会更快些）。然而，如果此类查询使用LIMIT只搜索部分行，MySQL则使用索引，因为它可以更快地找到几行并在结果中返回。例如：1234567mysql&gt; EXPLAIN SELECT * FROM t_web_log WHERE module = &apos;admin&apos;;+----+-------------+-----------+------+---------------+------+---------+------+-------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+---------------+------+---------+------+-------+-------------+| 1 | SIMPLE | t_web_log | ALL | module | NULL | NULL | NULL | 16676 | Using where |+----+-------------+-----------+------+---------------+------+---------+------+-------+-------------+1 row in set (0.00 sec) 合理的建立索引的建议 越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和CPU缓存中都需要更少的空间，处理起来更快。 简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应该用内置的日期和时间数据类型，而不是用字符串来存储时间；以及用整型数据类型存储IP地址。 尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值 这部分是关于索引和写SQL语句时应当注意的一些琐碎建议和注意点。 123456781. 当结果集只有一行数据时使用LIMIT 12. 避免SELECT *，始终指定你需要的列,从表中读取越多的数据，查询会变得更慢。他增加了磁盘需要操作的时间，还是在数据库服务器与WEB服务器是独立分开的情况下。你将会经历非常漫长的网络延迟，仅仅是因为数据不必要的在服务器之间传输。3. 使用连接（JOIN）来代替子查询(Sub-Queries),连接（JOIN）.. 之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作,但是两个大表尽量不要联表查询。4. 使用ENUM、CHAR 而不是VARCHAR，使用合理的字段属性长度5. 尽可能的使用NOT NULL6. 固定长度的表会更快7. 拆分大的DELETE 或INSERT 语句8. 查询的列越小越快 Where条件在查询中，WHERE条件也是一个比较重要的因素，尽量少并且是合理的where条件是很重要的，尽量在多个条件的时候，把会提取尽量少数据量的条件放在前面，减少后一个where条件的查询时间。 有些where条件会导致索引无效： where子句的查询条件里有！=，MySQL将无法使用索引。 where子句使用了Mysql函数的时候，索引将无效，比如：select * from tb where left(name, 4) = ‘xxx’ 使用LIKE进行搜索匹配的时候，这样索引是有效的：select * from tbl1 where name like ‘xxx%’，而like ‘%xxx%’ 时索引无效 三、配置优化安装MySQL后，配置文件my.cnf在 /MySQL安装目录/share/mysql目录中，该目录中还包含多个配置文件可供参考，有my-large.cnf ，my-huge.cnf， my-medium.cnf，my-small.cnf，分别对应大中小型数据库应用的配置。win环境下即存在于MySQL安装目录中的.ini文件。 下面列出了对性能优化影响较大的主要变量，主要分为连接请求的变量和缓冲区变量。 请求的变量 max_connections MySQL的最大连接数，增加该值增加mysqld 要求的文件描述符的数量。如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。 数值过小会经常出现ERROR 1040: Too many connections错误，可以过’conn%’通配符查看当前状态的连接数量，以定夺该值的大小。 123show variables like ‘max_connections’ 最大连接数show status like ‘max_used_connections’响应的连接数 如下：1234567891011121314151617181920212223mysql&gt; show variables like ‘max_connections‘;+———————–+——-+| Variable_name | Value |+———————–+——-+| max_connections | 256 |+———————–+——-+mysql&gt; show status like ‘max%connections‘;+———————–+——-+| Variable_name | Value |+—————————-+——-+| max_used_connections | 256|+—————————-+——-+ max_used_connections / max_connections * 100% （理想值≈ 85%）如果max_used_connections跟max_connections相同 那么就是max_connections设置过低或者超过服务器负载上限了，低于10%则设置过大。 back_log MySQL能暂存的连接数量。当主要MySQL线程在一个很短时间内得到非常多的连接请求，这就起作用。如果MySQL的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。 back_log值指出在MySQL暂时停止回答新请求之前的短时间内有多少个请求可以被存在堆栈中。只有如果期望在一个短时间内有很多连接，你需要增加它，换句话说，这值对到来的TCP/IP连接的侦听队列的大小。 当观察你主机进程列表（mysql&gt; show full processlist），发现大量264084 | unauthenticated user | xxx.xxx.xxx.xxx | NULL | Connect | NULL | login | NULL 的待连接进程时，就要加大back_log 的值了。 默认数值是50，可调优为128，对于Linux系统设置范围为小于512的整数。 interactive_timeout一个交互连接在被服务器在关闭前等待行动的秒数。一个交互的客户被定义为对mysql_real_connect()使用CLIENT_INTERACTIVE 选项的客户。 默认数值是28800，可调优为7200。 缓冲区变量 全局缓冲： key_buffer_size key_buffer_size指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads / key_read_requests应该尽可能的低，至少是1:100，1:1000更好（上述状态值可以使用SHOW STATUS LIKE ‘key_read%’获得）。 key_buffer_size只对MyISAM表起作用。即使你不使用MyISAM表，但是内部的临时磁盘表是MyISAM表，也要使用该值。可以使用检查状态值created_tmp_disk_tables得知详情。 举例如下： 123456789101112131415161718192021222324252627mysql&gt; show variables like ‘key_buffer_size‘;+——————-+————+| Variable_name | Value |+———————+————+| key_buffer_size | 536870912 |+———— ———-+————+key_buffer_size为512MB，我们再看一下key_buffer_size的使用情况：mysql&gt; show global status like ‘key_read%‘;+————————+————-+| Variable_name | Value |+————————+————-+| Key_read_requests| 27813678764 || Key_reads | 6798830 |+————————+————-+ 一共有27813678764个索引读取请求，有6798830个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率： key_cache_miss_rate ＝Key_reads / Key_read_requests * 100%，设置在1/1000左右较好 默认配置数值是8388600(8M)，主机有4GB内存，可以调优值为268435456(256MB)。 query_cache_size 使用查询缓冲，MySQL将查询结果存放在缓冲区中，今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。 通过检查状态值Qcache_*，可以知道query_cache_size设置是否合理（上述状态值可以使用SHOW STATUS LIKE ‘Qcache%’获得）。如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况，如果Qcache_hits的值也非常大，则表明查询缓冲使用非常频繁，此时需要增加缓冲大小；如果Qcache_hits的值不大，则表明你的查询重复率很低，这种情况下使用查询缓冲反而会影响效率，那么可以考虑不用查询缓冲。此外，在SELECT语句中加入SQL_NO_CACHE可以明确表示不使用查询缓冲。 与查询缓冲有关的参数还有query_cache_type、query_cache_limit、query_cache_min_res_unit。 query_cache_type指定是否使用查询缓冲，可以设置为0、1、2，该变量是SESSION级的变量。 query_cache_limit指定单个查询能够使用的缓冲区大小，缺省为1M。 query_cache_min_res_unit是在4.1版本以后引入的，它指定分配缓冲区空间的最小单位，缺省为4K。检查状态值Qcache_free_blocks，如果该值非常大，则表明缓冲区中碎片很多，这就表明查询结果都比较小，此时需要减小query_cache_min_res_unit。 举例如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445mysql&gt; show global status like ‘qcache%‘;+——————————-+—————–+| Variable_name | Value |+——————————-+—————–+| Qcache_free_blocks | 22756 || Qcache_free_memory | 76764704 || Qcache_hits | 213028692 || Qcache_inserts | 208894227 || Qcache_lowmem_prunes | 4010916 || Qcache_not_cached | 13385031 || Qcache_queries_in_cache | 43560 || Qcache_total_blocks | 111212 |+——————————-+—————–+mysql&gt; show variables like ‘query_cache%‘;+————————————–+————–+| Variable_name | Value |+————————————–+———–+| query_cache_limit | 2097152 || query_cache_min_res_unit | 4096 || query_cache_size | 203423744 || query_cache_type | ON || query_cache_wlock_invalidate | OFF |+————————————–+—————+ 查询缓存碎片率= Qcache_free_blocks / Qcache_total_blocks * 100% 如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。 查询缓存利用率= (query_cache_size – Qcache_free_memory) / query_cache_size * 100% 查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小；查询缓存利用率在80％以上而且Qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。 查询缓存命中率= (Qcache_hits – Qcache_inserts) / Qcache_hits * 100% 示例服务器查询缓存碎片率＝20.46％，查询缓存利用率＝62.26％，查询缓存命中率＝1.94％，命中率很差，可能写操作比较频繁吧，而且可能有些碎片。 每个连接的缓冲 record_buffer_size每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，你可能想要增加该值。 默认数值是131072(128K)，可改为16773120 (16M) read_rnd_buffer_size随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 一般可设置为16M sort_buffer_size每个需要进行排序的线程分配该大小的一个缓冲区。增加这值加速ORDER BY或GROUP BY操作。 默认数值是2097144(2M)，可改为16777208 (16M)。 join_buffer_size联合查询操作所能使用的缓冲区大小 record_buffer_size，read_rnd_buffer_size，sort_buffer_size，join_buffer_size为每个线程独占，也就是说，如果有100个线程连接，则占用为16M*100 table_cache表高速缓存的大小。每当MySQL访问一个表时，如果在表缓冲区中还有空间，该表就被打开并放入其中，这样可以更快地访问表内容。通过检查峰值时间的状态值Open_tables和Opened_tables，可以决定是否需要增加table_cache的值。如果你发现open_tables等于table_cache，并且opened_tables在不断增长，那么你就需要增加table_cache的值了（上述状态值可以使用SHOW STATUS LIKE ‘Open%tables’获得）。注意，不能盲目地把table_cache设置成很大的值。如果设置得太高，可能会造成文件描述符不足，从而造成性能不稳定或者连接失败。 1G内存机器，推荐值是128－256。内存在4GB左右的服务器该参数可设置为256M或384M。 max_heap_table_size用户可以创建的内存表(memory table)的大小。这个值用来计算内存表的最大行数值。这个变量支持动态改变，即set @max_heap_table_size=# 这个变量和tmp_table_size一起限制了内部内存表的大小。如果某个内部heap（堆积）表大小超过tmp_table_size，MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。 tmp_table_size通过设置tmp_table_size选项来增加一张临时表的大小，例如做高级GROUP BY操作生成的临时表。如果调高该值，MySQL同时将增加heap表的大小，可达到提高联接查询速度的效果，建议尽量优化查询，要确保查询过程中生成的临时表在内存中，避免临时表过大导致生成基于硬盘的MyISAM表。 123456789101112131415mysql&gt; show global status like ‘created_tmp%‘;+——————————–+———+| Variable_name | Value |+———————————-+———+| Created_tmp_disk_tables | 21197 || Created_tmp_files | 58 || Created_tmp_tables | 1771587 |+——————————–+———–+ 每次创建临时表，Created_tmp_tables增加，如果临时表大小超过tmp_table_size，则是在磁盘上创建临时表，Created_tmp_disk_tables也增加,Created_tmp_files表示MySQL服务创建的临时文件文件数，比较理想的配置是： Created_tmp_disk_tables / Created_tmp_tables 100% &lt;= 25%比如上面的服务器Created_tmp_disk_tables / Created_tmp_tables 100% ＝1.20%，应该相当好了 默认为16M，可调到64-256最佳，线程独占，太大可能内存不够I/O堵塞 thread_cache_size可以复用的保存在中的线程的数量。如果有，新的线程从缓存中取得，当断开连接的时候如果有空间，客户的线置在缓存中。如果有很多新的线程，为了提高性能可以这个变量值。 通过比较 Connections和Threads_created状态的变量，可以看到这个变量的作用。 默认值为110，可调优为80。 thread_concurrency推荐设置为服务器 CPU核数的2倍，例如双核的CPU, 那么thread_concurrency的应该为4；2个双核的cpu, thread_concurrency的值应为8。默认为8 wait_timeout指定一个请求的最大连接时间，对于4GB左右内存的服务器可以设置为5-10。 配置InnoDB的几个变量 innodb_buffer_pool_size 对于InnoDB表来说，innodb_buffer_pool_size的作用就相当于key_buffer_size对于MyISAM表的作用一样。InnoDB使用该参数指定大小的内存来缓冲数据和索引。对于单独的MySQL数据库服务器，最大可以把该值设置成物理内存的80%。 根据MySQL手册，对于2G内存的机器，推荐值是1G（50%）。 innodb_flush_log_at_trx_commit 主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点，取值分别为0、1、2三个。0，表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入日志文件并flush磁盘一次；1，则在每秒钟或是每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；设置为2，每次事务提交引起写入日志文件的动作，但每秒钟完成一次flush磁盘操作。 实际测试发现，该值对插入数据的速度影响非常大，设置为2时插入10000条记录只需要2秒，设置为0时只需要1秒，而设置为1时则需要229秒。因此，MySQL手册也建议尽量将插入操作合并成一个事务，这样可以大幅提高速度。 根据MySQL手册，在允许丢失最近部分事务的危险的前提下，可以把该值设为0或2。 innodb_log_buffer_size log缓存大小，一般为1-8M，默认为1M，对于较大的事务，可以增大缓存大小。 可设置为4M或8M。 innodb_additional_mem_pool_size 该参数指定InnoDB用来存储数据字典和其他内部数据结构的内存池大小。缺省值是1M。通常不用太大，只要够用就行，应该与表结构的复杂度有关系。如果不够用，MySQL会在错误日志中写入一条警告信息。 根据MySQL手册，对于2G内存的机器，推荐值是20M，可适当增加。 innodb_thread_concurrency=8 推荐设置为 2*(NumCPUs+NumDisks)，默认一般为8","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/索引/"},{"name":"慢查询","slug":"慢查询","permalink":"http://yoursite.com/tags/慢查询/"}]},{"title":"mysql索引的数据结构和算法","date":"2017-10-19T06:40:21.000Z","path":"2017/10/19/mysql索引的数据结构和算法/","text":"摘要大学里面，学习数据结构与算法时，里面讲到：程序=数据结构+算法，不过写了这几年代码，始终没感觉有用到数据结构和算法。近来，偶尔看到有文章写mysql索引后的数据结构和算法，颇有收获，特此记录下重点。 文章主要分三部分： 从数据结构及算法理论层面讨论MySQL数据库索引的数理基础。 MySQL数据库中MyISAM和InnoDB数据存储引擎中索引的架构实现讨论聚集索引、非聚集索引及覆盖索引等 探讨如何在MySQL中高性能使用索引的 数据结构和算法索引本质 MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。 我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 看个例子 图中展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)O(log2n)的复杂度内获取到相应数据。 这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。 B-Tree和B+Tree目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。 B-Tree为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构： d为大于1的一个正整数，称为B-Tree的度。2.h为一个正整数，称为B-Tree的高度。 每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d。 每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。5.所有叶节点具有相同的深度，等于树高h。6.key和指针互相间隔，节点两端是指针。7.一个节点中的key从左到右非递减排列。8.所有节点组成树结构。 每个指针要么为null，要么指向另外一个节点。 如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。 如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。 如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。 如图是个d=2的B-Tree示意图 由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下： 123456789101112BTree_Search(node, key)&#123; if(node == null) return null; foreach(node.key) &#123; if(node.key[i] == key) return node.data[i]; if(node.key[i] &gt; key) return BTree_Search(point[i]-&gt;node); &#125; return BTree_Search(point[i+1]-&gt;node);&#125; data = BTree_Search(root, my_key); 关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为logd((N+1)/2)，检索一个key，其查找节点个数的渐进复杂度为O(logdN)。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。 另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法。 B+TreeB-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。 与B-Tree相比，B+Tree有以下不同点：1.每个节点的指针上限为2d而不是2d+1。2.内节点不存储data，只存储key；叶子节点不存储指针。 如图所示是个简单的B+Tree MySQL索引实现在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。 MyISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 这里设表一共有三列，假设我们以Col1为主键，则图中是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示： 同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分 InnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 图中是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引： 这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 如何在MySQL中高性能使用索引，将会在下一篇文章继续探讨 ​","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/索引/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"private和protected的问题","date":"2017-10-12T12:08:59.000Z","path":"2017/10/12/private和protected的问题/","text":"一、二者区别 加上public 内部 子类 外部 public √ √ √ protected √ √ × private √ × × 二、问题分析(1)看下面两段代码 代码1 12345678910111213141516171819202122232425class Human &#123; protected $name = &apos;li san&apos;; protected $money; public $age ;&#125;class Stu extends Human &#123; public function __construct() &#123; $this-&gt;name = &apos;li si&apos;; $this-&gt;money = 300; $this-&gt;age = 26; &#125; private $friend = &apos;zhang san&apos;; public function talk() &#123; echo &apos;我叫&apos;.$this-&gt;name.PHP_EOL; &#125;&#125;$ming = new Stu();$ming-&gt;talk();echo $ming-&gt;name.PHP_EOL; 运行结果：12我叫li siPHP Fatal error: Cannot access protected property Stu::$name 将类human中的name属性改为 private，得到代码2 代码2 12345678910111213141516171819202122232425class Human &#123; private $name = &apos;li san&apos;; protected $money; public $age ;&#125;class Stu extends Human &#123; public function __construct() &#123; $this-&gt;name = &apos;li si&apos;; $this-&gt;money = 300; $this-&gt;age = 26; &#125; private $friend = &apos;zhang san&apos;; public function talk() &#123; echo &apos;我叫&apos;.$this-&gt;name.PHP_EOL; &#125;&#125;$ming = new Stu();$ming-&gt;talk();echo $ming-&gt;name.PHP_EOL; 运行结果：12我叫li sili si (2)结论 代码1中name属性为protected ，代码2中为private，为什么在代码1中访问name会报错，反而2中不会报错 根据上面的private和protected的区别，父类的name为private时，子类时访问不到的，此时子类的构造方法里面$this-&gt;name，相当于==新建了一个name属性且为public==，所以能访问；父类的name为protected时，==子类修改的其实是继承过来的protected属性==，外部当然不能访问了","tags":[{"name":"问题探究","slug":"问题探究","permalink":"http://yoursite.com/tags/问题探究/"}]},{"title":"php浮点数问题","date":"2017-10-07T07:44:58.000Z","path":"2017/10/07/php浮点数问题/","text":"一、两个浮点数运算问题1、小数乘以100 代码： 1234$a = 20.40;echo $a.PHP_EOL;$b = intval($a*100);echo $b.PHP_EOL; 结果： 1220.42039 再看另一段代码： 1234567$a = 20.4;$b = $a * 100; //其实很多小数都有类似问题，也不限于PHPecho (string) $b . PHP_EOL;echo (int) $b .PHP_EOL;echo floor($b) .PHP_EOL;echo ceil($b) . PHP_EOL;echo (int)(string) $b . PHP_EOL; 运行结果： 1234520402039203920402040 2、两个浮点数比较大小 代码： 12345$a = 0.1;$b = 0.9;$c = 1;var_dump(($a+$b)==$c);var_dump(($c-$b)==$a); 运行结果： 12truefalse 看完这两个问题，我相信很多同学会有一种疑问，这个是php的bug吗？且看下面的问题分析 二、问题分析1、浮点数的表示要搞明白这个原因, 首先我们要知道浮点数的表示(IEEE 754): 浮点数, 以64位的长度(双精度)为例, 会采用1位符号位(E), 11指数位(Q), 52位尾数(M)表示(一共64位) 符号位：最高位表示数据的正负，0表示正数，1表示负数。 指数位：表示数据以2为底的幂，指数采用偏移码表示 尾数：表示数据小数点后的有效数字.然后我们需要了解的是浮点数如何转换为二进制数 2、浮现数转二进制方法 整数部分采用除以2取余方法 小数部分采用乘以2取整方法 例如： 把数字8.5转为二进制 整数部分是8 8/2=4 8%2=0 4/2=2 4%2=0 2/2=1 2%2=0 1比2小，因此不需要计算下去，整数8的二进制为 1000 小数部分是0.5 0.5x2 = 1.0 因取整后小数部分为0，因此不需要再计算下去 小数0.5的二进制为 0.1 8.5的二进制为1000.1 3、运算问题1 根据上面关于浮点数表示的解释，20.4转换为二进制64位浮点数为：0100000000110100011001100110011001100110011001100110011001100110,小数部分0.4转换为二进制来说，是无限长的，再乘以100时，截断52位来计算的话就是20.399999999…,再乘以100，int转换为整数，就是2039了 4、运算问题2这个问题中，0.9在转换为二进制时，同样也会有精度丢失的问题 看下面这段代码： 12345$a = 0.1;$b = 0.9;$c = 1;printf(&quot;%.20f&quot;, $a+$b);printf(&quot;%.20f&quot;, $c-$b); 运行结果： 121.000000000000000000000.09999999999999997780 三、综合1、简单乘法 我在开发时，曾经多次遇到小数乘以100，得到错误结果的问题，初步可以转换为string类型解决 2、高精度运算方法 使用高精度的运算方法，这样可以保证精度不丢失。 高精度运算的方法如下： bcadd 将两个高精度数字相加 bccomp 比较两个高精度数字，返回-1,0,1 bcdiv 将两个高精度数字相除 bcmod 求高精度数字余数 bcmul 将两个高精度数字相乘 bcpow 求高精度数字乘方 bcpowmod 求高精度数字乘方求模 bcscale 配置默认小数点位数，相当于Linux bc中的”scale=” csqrt 求高精度数字平方根 bcsub 将两个高精度数字相减 代码：12345$a = 0.1;$b = 0.9;$c = 1;var_dump(($c-$b)==$a);var_dump(bcsub($c, $b, 1)==$a); 运行结果：12falsetrue php计算的问题还有可能和操作系统的位数相关，比如32位和64位，这些大家可以研究下~","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"}]},{"title":"序言","date":"2017-10-06T03:53:03.000Z","path":"2017/10/06/随笔/","text":"一、由来1、前世 其实，在一年以前我就已经用hexo加github搭建过个人的博客。去年的时候，偶然看到我一个高中好哥们的博客,他的博客就是用hexo+github搭的，不过那个时候仅仅是想作为一个相册使用，里面放的都是我自己和女朋友的一些照片。后来，懒得去维护了，空间和域名都渐渐荒废了。之前的那个博客可以算的上是这个的前世 2、今生 前段时间申请了自己的一个域名:lili-web.com,想着去阿里云买一台服务器，搭一个自己的技术博客。去阿里云上的服务器看了下价格，摸了摸自己的荷包，并且买了服务器还得去备案，麻烦~正愁着咋办，我突然想起，自己一年多用github+hexo搭建博客，不仅免费，而且不用去备案。于是开干，在网上参考了别人搭建github博客的文章，花了一天多的时间，搭建了该博客！ 二、展望1、博客 先定一个小目标，比如说。。。。。，想多了。。。。，坚持每周写一篇博客，不管是技术的还是其他的 2、go 本人是从事php开发工作的，感觉php能做的事还是比较局限，进来在学习golang 3、money 我博客取名叫lemon，其实是取得“来 money”的意思，简称lemon~要结婚、还贷、装修等等，到处是花钱的地方，所以要赶紧挣钱了。。。大家有网站开发类的私活可以找我哈~","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"Github+Hexo搭建博客","date":"2017-10-05T08:30:44.000Z","path":"2017/10/05/Github-Hexo搭建博客/","text":"一、环境搭建1.NodeJS 安装NodeJS：http://nodejs.cn/download/ 下载.msi文件，不需要配置环境变量 2.github 安装git ssh工具：https://git-for-windows.github.io/ 配置git环境，推荐教程：https://www.liaoxuefeng.com 3.hexo 安装Hexo: npm install -g hexo 初始化Hexo: hexo init 生成静态页面：hexo generate 或者 hexo g 启动服务器：hexo server 或者 hexo s 浏览器中访问：http://localhost:4000 二、更换主题及主题配置1.更换主题 默认主题是landscape，在themes文件夹下，可以使用别人开发好的主题，这里有很多，我使用的是这一个: https://github.com/litten/hexo-theme-yilia下载之后放到themes文件夹下即可：git clone git@github.com:litten/hexo-theme-yilia.git 2.主题基本配置 注意，主题配置修改的都是themes/yilia/_config.yml，配置项不一一解释了 3.头像和打赏配置（1）图片的位置 图片应该放在当前博客下面，比如我建了一个img文件夹，图片就放在里面，如下图所示： （2）具体配置 1234567891011#打赏# 打赏type设定：0-关闭打赏； 1-文章对应的md文件里有reward:true属性，才有打赏； 2-所有文章均有打赏reward_type: 2# 打赏wordingreward_wording: &apos;谢谢你请我吃糖果&apos;# 支付宝二维码图片地址，跟你设置头像的方式一样。比如：/assets/img/alipay.jpgalipay: /img/alipay.png# 微信二维码图片地址weixin: /img/wepay.png# 头像地址avatar: /img/avatar.jpg ​ 三、博客的基本配置 注意：这里修改的都是最外层的_config.yml（不是themes文件夹里面） 1.所有文章 在_config.yml中配置如下，不加的话，点击所有文章会报错 123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: true raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 2.部署配置 配置到github对应的仓库中 在_config.yml中配置如下： 1234deploy: type: git repo: git@github.com:username/username.github.io.git branch: master 四、高级功能配置1、网站访问量显示（1）效果 （2） 实现 使用了不蒜子第三方的统计插件，网址：http://ibruce.info/2015/04/04/busuanzi/ 在themes\\yilia\\layout_partial下的footer.ejs中加入如下代码即可，如下所示： 12345678910111213141516171819202122&lt;footer id=&quot;footer&quot;&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div id=&quot;footer-info&quot;&gt; &lt;div class=&quot;footer-left&quot;&gt; &amp;copy; &lt;%= date(new Date(), &apos;YYYY&apos;) %&gt; &lt;%= config.author || config.title %&gt; &lt;/div&gt; &lt;div&gt; &lt;span id=&quot;busuanzi_container_site_pv&quot;&gt; 本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次 &lt;/span&gt; &lt;span id=&quot;busuanzi_container_site_uv&quot;&gt; 总访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次 &lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;footer-right&quot;&gt; &lt;a href=&quot;http://hexo.io/&quot; target=&quot;_blank&quot;&gt;Hexo&lt;/a&gt; Theme &lt;a href=&quot;https://github.com/litten/hexo-theme-yilia&quot; target=&quot;_blank&quot;&gt;Yilia&lt;/a&gt; by Litten &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/footer&gt;&lt;script async src=&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 2、评论功能（1）效果 （2）实现 去来必力网站注册账号，https://livere.com/ 网站给的代码，如图 插入的代码需要调整下边距，不然下面的第三方登录按钮会被覆盖导致错位，我加的代码如下 1style=&quot;margin: 0 50px 0 50px&quot; 最后在themes\\yilia\\layout_partial下的article.ejs将改代码添加到&lt;% if (theme.wangyiyun){ %&gt;前面 12345678910111213141516171819202122232425&lt;!-- 来必力City版安装代码 --&gt; &lt;div id=&quot;lv-container&quot; data-id=&quot;city&quot; data-uid=&quot;MTAyMC8zMTIwOS83NzU4&quot; style=&quot;margin: 0 50px 0 50px&quot;&gt; &lt;script type=&quot;text/javascript&quot;&gt; (function(d, s) &#123; var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === &apos;function&apos;) &#123; return; &#125; j = d.createElement(s); j.src = &apos;https://cdn-city.livere.com/js/embed.dist.js&apos;; j.async = true; e.parentNode.insertBefore(j, e); &#125;)(document, &apos;script&apos;); &lt;/script&gt; &lt;noscript&gt; 为正常使用来必力评论功能请激活JavaScript&lt;/noscript&gt; &lt;/div&gt; &lt;!-- City版安装代码已完成 --&gt; &lt;% if (theme.wangyiyun)&#123; %&gt; &lt;%- partial(&apos;post/wangyiyun&apos;, &#123; key: post.slug, title: post.title, url: config.url+url_for(post.path) &#125;) %&gt; &lt;% &#125; %&gt; 五、域名绑定1、申请域名 本人是在阿里云上面申请的域名，注意.com域名不需要备案，.cn是国内域名，需要备案 2、域名解析 ping username.github.io，来获取你的空间的ip 添加CNAME类型的解析 添加结果如图： 3、配置到github 在博客的根目录下新建一个CNAME文件 填写申请的域名，xxx.com push到github即可 六、感谢 本文参考了Lawlite的：Hexo+Github搭建自己的博客并按照步骤一步步搭建，几个模块的搭建方法有些许不同，在Lawlite的基础上做了修改，编写了这篇博客！","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"Hello World","date":"2017-10-05T08:00:03.681Z","path":"2017/10/05/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]